{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "### 1. train test split from scratch\n",
    "\n",
    "Create a function my_train_test_split() that takes ipnput X, y and fraction of train. And ouputs the list or tuple containing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "[[ 1  2  0]\n",
      " [ 3  4  1]\n",
      " [ 5  6  1]\n",
      " [ 7  8  0]\n",
      " [ 9 10  1]\n",
      " [11 12  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0], [9, 10, 1], [11, 12, 0]])\n",
    "print('data:')\n",
    "print(data)\n",
    "\n",
    "def my_train_test_split(X_train, y_train, split_percent= 0.8):\n",
    "    split = int(X.shape[0] * split_percent)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = data[:split, :-1]\n",
    "    y_train = data[:split, -1]\n",
    "    X_test = data[split:, :-1]\n",
    "    y_test = data[split:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "y_train:\n",
      "[0 1 1 0]\n",
      "X_test:\n",
      "[[ 9 10]\n",
      " [11 12]]\n",
      "y_test:\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your function invocation goes here\n",
    "X = data[:, :-1]  # Features\n",
    "y = data[:, -1]   # Labels\n",
    "\n",
    "train_frac = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "X_train, y_train, X_test, y_test = my_train_test_split(X, y, train_frac)\n",
    "\n",
    "# Printing the results\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"y_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN class that allows setting the number of neighbours and weight=uniform or distance\n",
    "class KNN:\n",
    "    def __init__(self, k = 7): #Fill this out\n",
    "        self.k = k\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train): # What is missing in function definition?\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        pass\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def predict(self, X_test): # What is missing in function definition?\n",
    "            y_pred = [self._predict(x) for x in X_test]\n",
    "            return np.array(y_pred)\n",
    "            pass\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # Return the most common class label\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "         y_pred = self.predict(X_test)\n",
    "         accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "         return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(k=7)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels:\n",
      "[0 0]\n",
      "True Labels:\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Labels:\")\n",
    "print(y_pred)\n",
    "print(\"True Labels:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "ks = range(1,30)\n",
    "for k in ks:\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.evaluate(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GridSearch from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "[[ 1  2  0]\n",
      " [ 3  4  1]\n",
      " [ 5  6  1]\n",
      " [ 7  8  0]\n",
      " [ 9 10  1]\n",
      " [11 12  0]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0], [9, 10, 1], [11, 12, 0]])\n",
    "print('data:')\n",
    "print(data)\n",
    "\n",
    "def my_train_test_split(X_train, y_train, split_percent= 0.8):\n",
    "    split = int(X.shape[0] * split_percent)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = data[:split, :-1]\n",
    "    y_train = data[:split, -1]\n",
    "    X_test = data[split:, :-1]\n",
    "    y_test = data[split:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "y_train:\n",
      "[0 1 1 0]\n",
      "X_test:\n",
      "[[ 9 10]\n",
      " [11 12]]\n",
      "y_test:\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "X = data[:, :-1]  # Features\n",
    "y = data[:, -1]   # Labels\n",
    "\n",
    "train_frac = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "X_train, y_train, X_test, y_test = my_train_test_split(X, y, train_frac)\n",
    "\n",
    "# Printing the results\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"y_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (2, 2) (4,) (2,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNN()\n",
    "# k_range = list(range(1,10, 2))\n",
    "# dist_metrics = ['euclidian', 'manhattan']    \n",
    "# k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # param_grid = {('n_neighbors': [range(1,10,2)],  'dist': ['euclidian'])}\n",
    "# para_grid = dict(n_neighbors = k_range)\n",
    "# grid = GridSearchCV(knn, para_grid, cv=10, scoring= 'accuracy', return_train_score=False, verbose=1)\n",
    "# grid_search = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [{\n",
    "#     'n_neighbors': [3, 5, 7, 9, 12,15,17],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     \\\n",
    "#     'metric': ['euclidean', 'manhattan']}]\n",
    "# grid = GridSearchCV(knn, params, cv=10, scoring= 'accuracy', return_train_score=False, verbose=1)\n",
    "# grid_search = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(3, 8, 2))\n",
    "weight_values = ['uniform', 'distance']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_k = None\n",
    "best_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, k=7, weight=['uniform', 'distance']):\n",
    "        self.k = k\n",
    "        self.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\AML\\AML-AIML\\KNN+Grid_search\\knn_GridSearch.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m product\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, weight \u001b[39min\u001b[39;00m product(k_values, weight_values):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     knn \u001b[39m=\u001b[39m KNN(k \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, weight \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mdistance\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     knn\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mevaluate(X, y)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'weight'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "        \n",
    "for k, weight in product(k_values, weight_values):\n",
    "    knn = KNN(k = 5, weight = 'distance')\n",
    "    knn.fit(X, y)\n",
    "    accuracy = knn.evaluate(X, y)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "            best_metric = weight\n",
    "\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Best weight: {best_metric}\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def grid_search(params1, params2, x_train, y_train, x_test, y_test):\n",
    "    hyper_params = list(product(params1, params2))\n",
    "    max_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    for i in hyper_params:\n",
    "        knn = KNeighborsClassifier(n_neighbors=i[0], weights=i[1])\n",
    "        knn.fit(x_train, y_train)\n",
    "        y_pred = knn.predict(x_test)\n",
    "        acc = metrics.accuracy_score(y_test, y_pred)\n",
    "        if acc > max_score:\n",
    "            max_score = acc\n",
    "            best_params = (i[0], i[1])\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = [1, 3, 5, 7]\n",
    "params2 = ['uniform', 'distance'] \n",
    "best_params = grid_search(params1, params2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"Best Hyperparameters (k, weights):\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Integrate your custom code\n",
    "\n",
    "1. Create a dataframe of iris dataset\n",
    "2. Use your custom train test split function to split into train and test\n",
    "3. Use your custom GridSearch on your customKNN class to identify the best k and best weight for iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "def my_train_test_split(X_train, y_train, train_frac= 0.8):\n",
    "    split = int(X.shape[0] * train_frac)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = df_iris[:split, :-1]\n",
    "    y_train = df_iris[:split, -1]\n",
    "    X_test = df_iris[split:, :-1]\n",
    "    y_test = df_iris[split:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, 120, None), slice(None, -1, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, 120, None), slice(None, -1, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\AML\\AML-AIML\\KNN+Grid_search\\knn_GridSearch.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m df_iris\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m df_iris[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m my_train_test_split(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_frac \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m  \u001b[39m# 80% for training, 20% for testing\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m my_train_test_split(X, y, train_frac)\n",
      "\u001b[1;32md:\\AML\\AML-AIML\\KNN+Grid_search\\knn_GridSearch.ipynb Cell 28\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m split \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m train_frac)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train \u001b[39m=\u001b[39m df_iris[:split, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_train \u001b[39m=\u001b[39m df_iris[:split, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AML/AML-AIML/KNN%2BGrid_search/knn_GridSearch.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_test \u001b[39m=\u001b[39m df_iris[split:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ATISHAY SG\\anaconda3\\envs\\AIMLSem1\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, 120, None), slice(None, -1, None))"
     ]
    }
   ],
   "source": [
    "X = df_iris.iloc[:, :-1].values\n",
    "y = df_iris['target'].values\n",
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y)\n",
    "train_frac = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "X_train, y_train, X_test, y_test = my_train_test_split(X, y, train_frac)\n",
    "\n",
    "# Printing the results\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"y_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 1\n",
      "Best weight: uniform\n",
      "Best accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset and create a DataFrame\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "# Define your custom train-test split function\n",
    "def my_train_test_split(X, y, train_fraction=0.8):\n",
    "    data = np.column_stack((X, y))\n",
    "    np.random.shuffle(data)\n",
    "    split = int(train_fraction * data.shape[0])\n",
    "    X_train, y_train = data[:split, :-1], data[:split, -1]\n",
    "    X_test, y_test = data[split:, :-1], data[split:, -1]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Split the dataset using your custom function\n",
    "X = iris_df.iloc[:, :-1].values\n",
    "y = iris_df['target'].values\n",
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y)\n",
    "\n",
    "# Define your custom KNN class with weight parameter\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=3, weight='uniform'):\n",
    "        self.k = k\n",
    "        self.weight = weight\n",
    "        # Add other necessary methods for fitting and predicting\n",
    "\n",
    "# Define hyperparameter values for grid search\n",
    "k_values = [1, 3, 5, 7]  # Different values of k\n",
    "weight_values = ['uniform', 'distance']  # Different weight options\n",
    "\n",
    "# Initialize variables to store the best hyperparameters and accuracy\n",
    "best_accuracy = 0\n",
    "best_k = None\n",
    "best_weight = None\n",
    "\n",
    "# Perform grid search by iterating over hyperparameter combinations\n",
    "for k, weight in product(k_values, weight_values):\n",
    "    custom_knn = CustomKNN(k=k, weight=weight)\n",
    "    # Train custom_knn using X_train and y_train\n",
    "    # Predict using X_test\n",
    "    # Calculate accuracy using y_test and store it in the 'accuracy' variable\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "        best_weight = weight\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Best weight: {best_weight}\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMLSem1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
